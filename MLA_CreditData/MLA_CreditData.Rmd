---
title: "Applying Machine Learning Algorithms to Determine Credit-Worthiness"
output:
  html_document: default
---
## Problem Statement
This project allows us to analyze a dataset with a binary response. The data comes from the CASdatasets library which is the dataset called credit. It contains 1,000 credit observations and 21 variables. The binary response variable class has values of 0 meaning credit-worthy, and 1 for not credit-worthy. So that means we will have to identify the important predictors of the remaining 20 variables by doing a descriptive analysis before applying different methods to predict the response variable.

## Learning the Data
```{r, warning = FALSE, message=FALSE}
library(xts)
library(sp)
library(CASdatasets)
data(credit)
str(credit) #examine which variables are factors or continuous
```
The first thing that I noticed is that majority of the predictors are categorical variables. Even some of the numeric predictors act as factors because they are integers that act as numeric rankings. For example, installment_rate are integers ranging from 1-4. When running the code ?credit, it shows that installment rate is in percentage of disposable income but instead of integers being listed, they have categorical rankings as you can see below. I'm not sure why it shows as categorical rankings here but as integers in the original dataset. The same goes for residence_since and existing_credits. The true continuous variables I would say are duration, credit_amount, age, and num_dependents.

Another step I took in the data cleaning process was to turn four of the categorical variables into numeric rankings. This is because when I studied each of the predictors, these four variables would be more interpretable as numeric variables. For example, checking_status is a factor with 4 levels as you can see below. I changed A11 as 1, A12 as 2, A13 as 3, and A14 as 0 because that means the individual doesn't have an existing checking account. I did similar rankings with savings, employment, and telephone. 
```{r, message=FALSE}
#checking_status: status of existing checking account (4 levels)
credit$checking_status <- as.numeric(credit$checking_status)
credit$checking_status <- ifelse(credit$checking_status==4,0,credit$checking_status) #set no checking account equal to 0
#savings: status of existing checking account (5 levels)
credit$savings <- as.numeric(credit$savings)
credit$savings <- ifelse(credit$savings==5,0,credit$savings) #set no savings account to 0
#employment: present employment since (5 levels)
credit$employment <- as.numeric(credit$employment)
#telephone: has telephone or not (2 levels)
credit$telephone <- as.numeric(credit$telephone)
credit$telephone <- ifelse(credit$telephone==2,0,credit$telephone) #set no telephone to 0
#convert dataset into dataframe and attach
credit <- data.frame(credit)
attach(credit)
```
After the data cleaning process I applied descriptive analysis to explore the data. First, I wanted to examine the correlation coefficients between each of the numeric variables and the response variable class.
```{r}
cor(credit[,c(1,2,6,7,8,11,13,16,18,19,21)])[,"class"]
```
Notice that duration, checking_status, employment, and age have the highest correlation coefficients ranging from |-0.09| to 0.22. Even though the coefficients aren't high, they show that there is some linear relationship between these variables and class. To visualize this, I plotted boxplots for these four variables.
```{r}
par(mfrow=c(2,2))
boxplot(duration~class,main="Credit Duration vs. Credit-Worthiness")
boxplot(checking_status~class,main="Checking Status vs. Credit-Worthiness")
boxplot(employment~class,main="Employment vs. Credit-Worthiness")
boxplot(age~class,main="Age vs. Credit-Worthiness")
```

The "Credit Duration vs. Credit-Worthiness" boxplot shows that typically, those who are not credit-worthy (class 1) have higher credit duration in months. Although, there are some individuals who are credit-worthy (class 0) who have high credit duration and are considered outliers. The next two plots shows that class 0 and class 1 both have equal medians as you can see with the thick black lines being at the same level. The last plot shows that typically, those who are credit-worthy are older on average.

The amount that one asks for when trying to open a credit line seems very important when determining who is credit-worthy and who's not. So, I wanted to examine the descriptive statistics of the continuous variable credit_amount.
```{r}
data.frame("Mean"=mean(credit_amount),"Variance"=var(credit_amount),"Median"=median(credit_amount))
```
On average, individuals request about 3,271 in Deutsch marks. Also, notice that the variance is very large at 7,967,843. Meaning, there are a lot of individuals who request a credit amount way higher than 3,271. Here is a boxplot showing those outliers in both class 0 and class 1.
```{r}
boxplot(credit_amount~class,main="Credit Amount vs. Credit-Worthiness")
```

I also wanted to examine some of the categorical variables that seemed important based on their context. I plotted barplots of the predictors credit_history, purpose, personal_status, and job to view their distribution among each class.
```{r}
par(mfrow=c(2,2))
barplot(table(class,credit_history),main="Credit History Distribution",
        legend=rownames(table(class,credit_history)),col=c("green","red"))
barplot(table(class,purpose),main="Purpose Distribution",
        legend=rownames(table(class,credit_history)),col=c("green","red"))
barplot(table(class,personal_status),main="Personal Status Distribution",
        legend=rownames(table(class,personal_status)),col=c("green","red"))
barplot(table(class,job),main="Job Distribution",
        legend=rownames(table(class,job)),col=c("green","red"))
```

When you look at the credit history distribution graph, you can see that most of the credit-worthy individuals are in category A32 (no credits taken or all credits paid back duly). Obviously, that makes sense and also there are more class 1 individuals (not credit-worthy) in categories A30 (delay in paying off in the past) and A31 (critical account). Also, most individual's purpose of credit is A43 (radio/television) with most being credit-worthy. Most non credit-worthy individuals borrow for the purpose of A40 (new car). The third graph shows that most borrowers are male and single and are mostly credit-worthy. The final graph shows that most credit-worthy individuals are categorized in the A173 class (skilled worker/skilled employee/minor civil servant).

## Splitting the Data
After examining the predictors, next step is to spit the data into a training set to train our models and a test set to test the trained models. For this analysis, I will split 70% as the training data and 30% as the test data by running a random sample.
```{r}
set.seed(1) #set seed
train = sample(1:nrow(credit), .7*nrow(credit)) #training sample
test = setdiff(1:nrow(credit), train) #test sample
credit.train = credit[train,] #training dataset
credit.test = credit[-train,] #test dataset
class.train = credit[train,"class"] #class values from training dataset
class.test = credit[-train,"class"] #class values from test dataset
```

## Logistic Regression
This first model I will use logistic regression on the training dataset using all predictors.
```{r, warning=FALSE}
library(glmnet)
glm.fit = glm(class~.,family=binomial,data=credit.train) #logisitic regression model
summary(glm.fit)
glm.probs = predict(glm.fit,newdata=credit.test,type="response") #returns probabilities
glm.pred = rep(0,length(glm.probs))
glm.pred[glm.probs>0.6] = 1 #chosen cutoff point: 0.6
mean((glm.pred-class.test)^2) #MSE
table(glm.pred,class.test) #confusion matrix
logreg_pa <- (193+30)/300 #prediction accuracy rate
```
The summary shows which predictors are significant according to this model by their p-value. Notice that checking_status, credit_historyA34, purposeA41, and purposeA43, are all very significant. I chose a cutoff point of 0.6 meaning if the returned probabilites given from the predict function is greater than 0.6, than classify that record as class 1. This gives a MSE of 0.2566667 or a 74.33% prediction accuracy rate. Also, when I ran the same model with just the predictors that are important checking_status, credit_history, and purpose, it actually gave a lower prediction accuracy so that's why I chose to stick with the original model using all predictors.

## Logistic Regression with LASSO
The next method I used is logistic regression with LASSO. Since p=20 (the number of predictors) is fairly large, LASSO is a reasonable method to use to shrink the coefficient estimates towards 0. LASSO performs variable selection and results in a model that is easier to interpret.
```{r}
set.seed(2)
train.matrix = model.matrix(class~.,data=credit.train) #design matrix for training dataset
test.matrix = model.matrix(class~.,data=credit.test) #design matrix for test dataset
grid = 10^seq(10,-2,length=100)
cv.out = cv.glmnet(train.matrix,class.train,alpha=1,family="binomial",type.measure="class",nfolds=10) #10-fold CV
plot(cv.out)
out = glmnet(train.matrix,class.train,alpha=1,lambda=grid,family="binomial") #LASSO model
bestlam.lasso = cv.out$lambda.min #best lambda based on cross validation
bestlam.lasso
lasso.prob=predict(out,test.matrix,s=bestlam.lasso)
lasso.pred = rep(0,300)
lasso.pred[lasso.prob>0.9]=1 #chosen cutoff point: 0.9
table(lasso.pred, class.test) #confusion matrix
logreg_lasso_pa <- (205+5)/300 #prediction accuracy rate
```
By using cross-validation to choose the tuning parameter λ, you can see from the plot that log(λ=0.00126789) = -6.670401 gives the lowest misclassification error. With a chosen cutoff point of 0.9, the prediction accuracy is 70% which is lower than the one calculated from just logistic regression. When I change the cutoff point, the prediction accuracy doesn't change that is why I chose a higher cutoff point that 0.5.

## Decision Tree with Pruning
A classification tree is used for a qualitative response. Even though our response is technically numeric, it's binary so it acts as a qualitative variable with 0 meaning credit-worthy and 1 meaning not credit-worthy. A classification tree assigns an observation in a given region to the most commonly occurring class of observations in that region.
```{r}
library(tree)
credit$class <- as.factor(credit$class) #change response from numeric to factor variable
credit.tree = tree(class~.,credit) #Establish a tree for the response variable class
summary(credit.tree)
plot(credit.tree) #Plot the decision tree
text(credit.tree, pretty=0, col="blue") #Add the labels for the nodes in the tree
```

From the information given by the summary command, the number of terminal nodes used is 7 and the misclassification error is 0.267 or a prediction accuracy rate of 73.3% This is higher than the logistic regression with LASSO model but lower than just the logistic regression model.

Next, I examined the prediction accuracy of the decision tree using cross validation using the subset as the training sample.
```{r}
credit.tree = tree(class~.,credit,subset=train) #Obtain the tree based on training set
tree.pred = predict(credit.tree,credit.test,type="class") #Get the prediction on the test set
table(tree.pred,class.test) #confusion matrix
dt_pa <- (167+35)/300 #prediction accuracy rate
```
The confusion matrix shows a prediction accuracy rate lowest of all at 67.33%. So this model is probably not the best in accurately predicting credit-worthiness. Another good strategy is to grow a large tree and prune it to obtain an optimal subtree, hopefully increasing the prediction accuracy rate. Below is the pruning procedure.
```{r}
set.seed(2)
cv.credit = cv.tree(credit.tree,FUN=prune.misclass)
cv.credit
par(mfrow=c(1,2))
plot(cv.credit$size,cv.credit$dev,type="b") #looks like size with minimum deviance is 8
plot(cv.credit$k,cv.credit$dev,type="b")
which.min(cv.credit$dev) #the minimum element is in the 3rd element of the output vectors
cv.credit$size[3] #8 nodes
prune.credit = prune.misclass(credit.tree,best=8) #Prune the tree to obtain the 8-node tree
par(mfrow=c(1,1))
plot(prune.credit)
text(prune.credit,pretty=0,col="blue")
tree.pred = predict(prune.credit,credit.test,type="class") #Use the pruned tree to predict the test set
table(tree.pred,class.test)
dt_8_pa <- (172+35)/300 #prediction accuracy
```
The number of terminal nodes that minimizes deviance when using cross validation is 8. This seems odd being that pruning is supposed to make a smaller tree, although it does give a slightly higher prediction accuracy rate of 69% than the non-pruned tree. Since the goal here is to reduce the number of terminal nodes, I chose to make a tree using less than 7 terminal nodes.
```{r}
prune.credit = prune.misclass(credit.tree,best=5) #use |T|=5
par(mfrow=c(1,1))
plot(prune.credit)
text(prune.credit,pretty=0,col="blue")
tree.pred = predict(prune.credit,credit.test,type="class")
table(tree.pred,class.test) #confusion matrix
dt_5_pa <- (166+43)/300 #prediction accuracy rate
```
Using a pruned tree with 5 terminal nodes gives a slightly higher prediction accuracy rate of 69.67% calculated from the confusion table.

## Bagging
The next method used is called bagging. Bagging is used to reduce the high variance of a single tree. It generates many trees and averages them out for the prediction on the response. First, we generate different training datasets by taking repeated samples and then for each training dataset, we estimate the response. Then finally, we average these predictions to get the estimation of the response for each record.
```{r}
set.seed(2)
library(randomForest)
credit.bag = randomForest(class~.,data=credit,subset=train,mtry=20,importance=TRUE) #model
credit.bag
#Error plot
plot(credit.bag)
credit.bag.legend <- if (is.null(credit.bag$test$err.rate)){colnames(credit.bag$err.rate)} else {colnames(credit.bag$test$err.rate)}
legend("top", cex =0.5, legend=credit.bag.legend, lty=c(1,2,3), col=c(1,2,3), horiz=T)
#Variable importance
varImpPlot(credit.bag,main="") #use importance(credit.bag) to view the values
bag.pred = predict(credit.bag,newdata=credit.test)
table(bag.pred,class.test) #confustion matrix
CM = table(bag.pred,class.test) #save confusion matrix to variable CM
bagging_pa <- (sum(diag(CM)))/sum(CM) #prediction accuracy
```
By setting mtry=20 means we are using all of the predictors which means we are using the bagging method. The prediction accuracy rate given by this model is 76%. The plot is an error plot with the x-axis as the number of trees and the y-axis as the error rate. As you can see, as the number of trees increases, the error rate decreases. The black plot is the overall Out-of-Bag error rate, the red is the class 0 error rate, and the green is the class 1 error rate. The importance of predictors are given in the next plot. The variables credit_amount, checking_status, duration, age, and purpose are all very importance predictors because they are shown at the very top of the second dot-plot. The importance is determined by the Gini index for classification trees. These predictors were mentioned before in the descriptive analysis part and proves that they are indeed important predictors.

By default, it creates 500 trees which is one of the issues with bagging. They are hard to interpret. So let's see how the model changes if we only change the parameter ntree (number of trees).
```{r}
set.seed(2)
credit.bag = randomForest(class~.,data=credit,subset=train,mtry=20,ntree=200) #200 trees
credit.bag
bag.pred = predict(credit.bag,newdata=credit.test)
table(bag.pred,class.test)
table(bag.pred,class.test) #confusion matrix
CM = table(bag.pred,class.test)
(sum(diag(CM)))/sum(CM) #prediction accuracy
```
I ran the model using different values for the number of trees less than 500 and no matter which value I set ntree equal to, I get a lower prediction accuracy than the model before using 500 trees. Although, the OOB error slightly improved.

## Random Forest
The last method used in this analysis is random forest. Instead of using all 20 predictors at each split, random forest selects a random sample of m predictors chosen from the full set of p predictors. Generally, p = √m for classification trees. By changing mtry=√20 (approximately 5) we are using random forest.
```{r}
set.seed(2)
credit.rf = randomForest(class~.,data=credit,subset=train,mtry=5,importance=TRUE)
credit.rf
plot(credit.rf)
varImpPlot(credit.rf)
rf.pred = predict(credit.rf,newdata=credit.test)
table(rf.pred,class.test) #confusion matrix
CM = table(rf.pred,class.test)
rf_pa <- (sum(diag(CM)))/sum(CM) #prediction accuracy rate
```
Notice that the OOB estimate of error is the same as the previous model but the prediction accuracy is lower. This model did not improve the model. This could be because most of the predictors are important and all act as strong predictors. Therefore, using a small set of predictors to build a tree would not reduce the trees' variance.

## Conclusion
There were 6 models that were obtained in this analysis using different methods: logistic regression, logistic regression with LASSO, decision tree before pruning, decision tree with pruning, bagging, and random forest. Of course, results from these models all vary by setting different parameters as shown. Here is a table summarizing the results obtained from each model.

```{r}
model.summary <- data.frame("Method"=c("Logistic Regression","Logistic Regression with LASSO","Decision Tree Before Pruning (7 Terminal Nodes)","Decision Tree with Pruning (5 Terminal Nodes)","Bagging","Random Forest"),
                            "Prediction Accuracy"=c(logreg_pa, logreg_lasso_pa, dt_pa, dt_5_pa, bagging_pa, rf_pa))
model.summary
```

The criteria I used to compare the five models is the prediction accuracy rate. I used this metric because it’s simple and easy to interpret. It’s the percentage of predictions that were correct. All of them show prediction accuracy rates that vary closely although, I think the globally best model based on this analysis is the bagging model. It has the highest prediction accuracy rate of 76% and it makes sense why it is an optimal method for this data. It reduces the high variance of a single tree and uses 500 trees and averages them out. This method is known to give impressive improvements in accuracy as shown in this analysis. Using all 20 predictors to be split at each tree is crucial as mentioned before because all of the predictors play an important role, that’s why random forest didn’t improve the model. One downfall of bagging is that it’s hard to interpret because there are 500 trees created to obtain 1 tree by averaging them out. Even though this is true, it still improves prediction accuracy which is why I think this is the optimal method when predicting who is credit-worthy and who is not credit-worthy.





